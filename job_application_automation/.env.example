# Database Configuration
DATABASE_URL=sqlite:///data/job_applications.db
DATABASE_POOL_SIZE=5
DATABASE_MAX_OVERFLOW=10
DATABASE_POOL_TIMEOUT=30
DATABASE_POOL_RECYCLE=1800

# LinkedIn API Configuration
LINKEDIN_CLIENT_ID=your_linkedin_client_id_here
LINKEDIN_CLIENT_SECRET=your_linkedin_client_secret_here
LINKEDIN_REDIRECT_URI=http://localhost:8000/linkedin/callback

# Llama Model Configuration
LLAMA_MODEL_PATH=../models/llama-4-mevrick
LLAMA_USE_GPU=True
LLAMA_GPU_LAYERS=32
LLAMA_NUM_THREADS=4

# API Integration Configuration
# Set to True to use API instead of local model
LLAMA_USE_API=True
# Choose one: "groq" or "openrouter"
LLAMA_API_PROVIDER=groq

# Model Name Configuration
# For Groq: llama-4-maverick
# For OpenRouter: meta/llama-4-maverick
LLAMA_API_MODEL=llama-4-maverick
GITHUB_TOKEN=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
# API Keys (choose one based on your provider)
GROQ_API_KEY=your_groq_api_key_here
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Application Settings
MAX_DAILY_APPLICATIONS=50
AUTO_APPLY_ENABLED=False
HEADLESS_MODE=True
DEBUG_MODE=False

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=json
LOG_FILE_PATH=data/logs/application.log


import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential
from dotenv import load_dotenv

endpoint = "https://models.github.ai/inference"
model = "meta/Llama-4-Maverick-17B-128E-Instruct-FP8"
load_dotenv()
token = os.environ["GITHUB_TOKEN"]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        SystemMessage("You are a helpful assistant."),
        UserMessage("What is the capital of France?"),
    ],
    temperature=1.0,
    top_p=1.0,
    max_tokens=1000,
    model=model
)

print(response.choices[0].message.content)
